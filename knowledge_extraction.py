# -*- coding: utf-8 -*-
"""knowledge_extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YQTKCYbEk49Kla6bi7dIiX1yr1KsCPyY

## Load the Data

Load the data from the file and remove the byte-codes
"""

from scipy.io import arff 
import pandas as pd

# Load arff file
data = arff.loadarff('/Project_Learning.arff')

# convert to pandas dataframe
df = pd.DataFrame(data[0])

# decode byte-string to string
df['allergy'] = df['allergy'].str.decode('utf-8') 
df['med'] = df['med'].str.decode('utf-8') 
df['disease'] = df['disease'].str.decode('utf-8') 
df['class'] = df['class'].str.decode('utf-8')

# print head of dataframe
df.head()

"""## Data Prepocessing

converting all the strings to numbers
"""

from sklearn import preprocessing


le = preprocessing.LabelEncoder()
df.allergy = le.fit_transform(df.allergy)
df.med = le.fit_transform(df.med)
df.disease = le.fit_transform(df.disease)
df.rename(columns = {'class':'CLASS'}, inplace = True)
df.CLASS = le.fit_transform(df.CLASS)
df.head()

"""## Visualizing the Data

In this step we can visualize the data by cloring it by class and by comparing all features with each other.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns; sns.set()
sns.pairplot(df, hue='CLASS', size=1.5);

"""## Splitting feature matrix and target array

We want to exclude our target feature `class` from our feature matrix and put it into it's own target array.
"""

# X_data is our feature matrix without class
X_data = df.drop("CLASS", axis=1)

# Y_data is the target array only containing class
Y_data = df["CLASS"]

# Test
print(X_data.shape)
print(Y_data.shape)

"""## Training Set

Splitting Data into training-set and test-set
"""

from sklearn import datasets
from sklearn.model_selection import train_test_split
Xtrain, Xtest, ytrain, ytest = train_test_split(X_data, Y_data,
                                               random_state=1)

"""## Building the Model

Building a Gaussian Naive Bayes Classification.
"""

from sklearn.naive_bayes import GaussianNB # 1. choose model class
model = GaussianNB()                       # 2. instantiate model
model.fit(Xtrain, ytrain)                  # 3. fit model to data
y_model = model.predict(Xtest)             # 4. predict on new data

"""## Validation of the Model

Testing the model with our Test set and calculating and accuracy score.
"""

from sklearn.metrics import accuracy_score
accuracy_score(ytest, y_model)

"""## Using the Model

Classifing patients from the test data.
"""

# prediction the class of every patient
# in the Xtest Dataframe
test_prediction = model.predict(Xtest)

print("predicted: [", end="")
for i in test_prediction:
  print(i, end=" ")

print("\b]\ncorrect:   [", end="")

for i in ytest:
  print(i, end =" ")

print("\b]")

"""## Alternative with Tensorflow"""

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import Model


model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(7, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(7, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])


training = model.fit(Xtrain.values, ytrain.values, validation_split=0.1, epochs=200, batch_size=10, verbose=2)

model.summary()

"""## Testing the accuracy"""

accuracy = model.evaluate(Xtrain, ytrain)
print(accuracy)

# Resultate mit tats√§chlichen Werten vergleichen

print(model.predict_classes(Xtest))
print("[", end="")

for i in ytest:
  print(i, end =" ")

print("\b]")

"""## Plotting the results"""

from matplotlib import pyplot as plt

history = training


plt.figure(figsize=(15,10))
plt.subplots_adjust(hspace=0.5)
plt.subplot(221) ; plt.title("loss")
plt.plot(history.history['loss'])
plt.subplot(222) ; plt.title("accuracy")
plt.plot(history.history['accuracy'])
plt.subplot(223) ; plt.title("val_loss")
plt.plot(history.history['val_loss'])
plt.subplot(224) ; plt.title("val_accuracy")
plt.plot(history.history['val_accuracy'])


plt.show()